# Deep Learning & Neural Network 
A collective experiments on Multi-layer perceptron (MLP), Convolution Nerual Network (CNN), Recurrent Neural Network (RNN), Long short-term memory (LSTM), Gated recurrent unit (GRU), and Graph Nerual Network (GNN) to train models for different datasets and tasks. All codes were written in Python.

### Multi-layer perceptron (MLP)
The goal in this experiment is to train a model with 784 features to predict the labels of 10 categories. This model uses the Multi-Layer Perceptron (MLP) method for prediction, and was experimented with adjusting different numbers of hidden layers, learning rate, optimizers, and loss function choices to improve the testing accuracy. The evaluation metrics include Accuracy, Precision, Recall, and F1 score.

### Convolution Nerual Network (CNN)

### Recurrent Neural Network (RNN), Long short-term memory (LSTM), and Gated recurrent unit (GRU)

### Graph Nerual Network (GNN)
